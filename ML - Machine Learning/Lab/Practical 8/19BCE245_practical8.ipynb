{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "19BCE245_Prac8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfN6PfBQu2ww"
      },
      "source": [
        "Date: **14.10.2021**\n",
        "\n",
        "Roll No. and Name: **19BCE245 Aayush Shah**\n",
        "\n",
        "Course Code and Name: **2CS501 Machine Learning**\n",
        "\n",
        "Practical: **8**\n",
        "\n",
        "Practical : **AND gate using Perceptron Learning (self-implementation) (2 Hrs)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhmcIQ_NnvX6"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "240AY74rnyiR"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCUDaOyTn1g2"
      },
      "source": [
        "# Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhkNSP24n7AG"
      },
      "source": [
        "data = pd.DataFrame(data = ([0,0,0],[0,1,0],[1,0,0],[1,1,1])) # converting dataframe to numpy array\n",
        "data=data.values\n",
        "n_datapoints = data.shape[0]    # number of input/output pairs\n",
        "n_dimensions=data.shape[1]-1    # number of attributes\n",
        "W = 2*np.random.random_sample(n_dimensions)-1   # randomly initializing weights between -1 to 1 "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUWVscGuoHGd"
      },
      "source": [
        "# Displaying Data Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTKtaR-eoJkk",
        "outputId": "5a2c7d4f-0ef4-4e2a-e821-193a212a573e"
      },
      "source": [
        "print(n_datapoints) \n",
        "print(n_dimensions) \n",
        "print(W)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "2\n",
            "[-0.40556093 -0.4577479 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0kL9eE7oNi4"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czhnbEQ5oPZQ",
        "outputId": "a6fd4f14-07b0-4dd2-cbcc-5d3b9d837ba9"
      },
      "source": [
        "b = np.random.random()    #  randomly initializing bias\n",
        "print(W, W.shape)     # printing weight and bias\n",
        "print(b)\n",
        "\n",
        "#initializing weights and bias\n",
        "lr=0.1\n",
        "n_epochs=50\n",
        "\n",
        "for i in range(n_epochs):\n",
        "  \n",
        "  for i in range(n_datapoints):   #inner for loop for presentation of all i/o pairs in an epoch \n",
        "    net_input = np.dot(W,data[i,0:n_dimensions])+b \n",
        "    a=net_input>=0\n",
        "    e=data[i,n_dimensions]-a    #error = target-actual\n",
        "    W = W + lr*e*(data[i,0:n_dimensions].T)   # updating weights and bias using perceptron learning rule \n",
        "    b=b + lr*e\n",
        "    print(i,W,b)\n",
        "\n",
        "#printing weights and biases\n",
        "print(W)\n",
        "print(b)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.40556093 -0.4577479 ] (2,)\n",
            "0.7625178372512018\n",
            "0 [-0.40556093 -0.4577479 ] 0.6625178372512018\n",
            "1 [-0.40556093 -0.5577479 ] 0.5625178372512019\n",
            "2 [-0.50556093 -0.5577479 ] 0.4625178372512019\n",
            "3 [-0.40556093 -0.4577479 ] 0.5625178372512019\n",
            "0 [-0.40556093 -0.4577479 ] 0.4625178372512019\n",
            "1 [-0.40556093 -0.5577479 ] 0.3625178372512019\n",
            "2 [-0.40556093 -0.5577479 ] 0.3625178372512019\n",
            "3 [-0.30556093 -0.4577479 ] 0.4625178372512019\n",
            "0 [-0.30556093 -0.4577479 ] 0.3625178372512019\n",
            "1 [-0.30556093 -0.4577479 ] 0.3625178372512019\n",
            "2 [-0.40556093 -0.4577479 ] 0.2625178372512019\n",
            "3 [-0.30556093 -0.3577479 ] 0.3625178372512019\n",
            "0 [-0.30556093 -0.3577479 ] 0.2625178372512019\n",
            "1 [-0.30556093 -0.3577479 ] 0.2625178372512019\n",
            "2 [-0.30556093 -0.3577479 ] 0.2625178372512019\n",
            "3 [-0.20556093 -0.2577479 ] 0.3625178372512019\n",
            "0 [-0.20556093 -0.2577479 ] 0.2625178372512019\n",
            "1 [-0.20556093 -0.3577479 ] 0.16251783725120192\n",
            "2 [-0.20556093 -0.3577479 ] 0.16251783725120192\n",
            "3 [-0.10556093 -0.2577479 ] 0.2625178372512019\n",
            "0 [-0.10556093 -0.2577479 ] 0.16251783725120192\n",
            "1 [-0.10556093 -0.2577479 ] 0.16251783725120192\n",
            "2 [-0.20556093 -0.2577479 ] 0.06251783725120191\n",
            "3 [-0.10556093 -0.1577479 ] 0.16251783725120192\n",
            "0 [-0.10556093 -0.1577479 ] 0.06251783725120191\n",
            "1 [-0.10556093 -0.1577479 ] 0.06251783725120191\n",
            "2 [-0.10556093 -0.1577479 ] 0.06251783725120191\n",
            "3 [-0.00556093 -0.0577479 ] 0.16251783725120192\n",
            "0 [-0.00556093 -0.0577479 ] 0.06251783725120191\n",
            "1 [-0.00556093 -0.1577479 ] -0.03748216274879809\n",
            "2 [-0.00556093 -0.1577479 ] -0.03748216274879809\n",
            "3 [ 0.09443907 -0.0577479 ] 0.06251783725120191\n",
            "0 [ 0.09443907 -0.0577479 ] -0.03748216274879809\n",
            "1 [ 0.09443907 -0.0577479 ] -0.03748216274879809\n",
            "2 [-0.00556093 -0.0577479 ] -0.1374821627487981\n",
            "3 [0.09443907 0.0422521 ] -0.03748216274879809\n",
            "0 [0.09443907 0.0422521 ] -0.03748216274879809\n",
            "1 [ 0.09443907 -0.0577479 ] -0.1374821627487981\n",
            "2 [ 0.09443907 -0.0577479 ] -0.1374821627487981\n",
            "3 [0.19443907 0.0422521 ] -0.03748216274879809\n",
            "0 [0.19443907 0.0422521 ] -0.03748216274879809\n",
            "1 [ 0.19443907 -0.0577479 ] -0.1374821627487981\n",
            "2 [ 0.09443907 -0.0577479 ] -0.2374821627487981\n",
            "3 [0.19443907 0.0422521 ] -0.1374821627487981\n",
            "0 [0.19443907 0.0422521 ] -0.1374821627487981\n",
            "1 [0.19443907 0.0422521 ] -0.1374821627487981\n",
            "2 [0.09443907 0.0422521 ] -0.2374821627487981\n",
            "3 [0.19443907 0.1422521 ] -0.1374821627487981\n",
            "0 [0.19443907 0.1422521 ] -0.1374821627487981\n",
            "1 [0.19443907 0.0422521 ] -0.2374821627487981\n",
            "2 [0.19443907 0.0422521 ] -0.2374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.1374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.1374821627487981\n",
            "1 [0.29443907 0.0422521 ] -0.2374821627487981\n",
            "2 [0.19443907 0.0422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.2374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.2374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.2374821627487981\n",
            "2 [0.19443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.2422521 ] -0.2374821627487981\n",
            "0 [0.29443907 0.2422521 ] -0.2374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "0 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "1 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "2 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "3 [0.29443907 0.1422521 ] -0.3374821627487981\n",
            "[0.29443907 0.1422521 ]\n",
            "-0.3374821627487981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5v67RBKo3RR"
      },
      "source": [
        "# Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IOFmrT6o41T",
        "outputId": "5b9c28da-ee79-42ee-e42c-763a96ea8130"
      },
      "source": [
        "prediction = (np.dot(data[:,0:n_dimensions],W)+b)>=0    # making prediction\n",
        "print(prediction)   # displaying prediction"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0zyKZ69qFMj"
      },
      "source": [
        "# Conclusion :\n",
        "- **Perceptron** : The perceptron method classifies patterns and groups by determining the linear separation between various items and patterns acquired via numeric or visual input.\n",
        "- From this practical, I learned that a perceptron is essentially a single layer neural network. It's a supervised learning linear binary classifier. It is divided into four parts :\n",
        "  1. Input Layer\n",
        "  2. Weights and  Bias\n",
        "  3. Net Sum\n",
        "  4. Activation Function\n",
        "- Weights reflect a node's strength, and bias allows us to adjust the activation function's curve upward or downward. The activation function is necessary to transfer input values between required values such as (0,1) or (-1,1).\n",
        "It's vital to realise that it can only learn simple problems. It can only be used, more accurately and technically, if the data is linearly separable.\n",
        "- When we say linearly separable, we imply that the classes should be separated by a single hyperplane.\n"
      ]
    }
  ]
}